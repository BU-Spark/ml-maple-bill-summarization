{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/b8/eb/234646d9eefda8a500d0fd88b05bf625a90ed18054124349db26e558276e/tiktoken-0.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tiktoken-0.5.1-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/b8/ad/3398312096118c4e62a5827664e52a04d5068e84d04142dd4a0da8a567ae/regex-2023.10.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.0 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 503.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\16178\\anaconda3\\envs\\llama\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\16178\\anaconda3\\envs\\llama\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\16178\\anaconda3\\envs\\llama\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\16178\\anaconda3\\envs\\llama\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\16178\\anaconda3\\envs\\llama\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Downloading tiktoken-0.5.1-cp311-cp311-win_amd64.whl (759 kB)\n",
      "   ---------------------------------------- 0.0/759.8 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/759.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 327.7/759.8 kB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 686.1/759.8 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 759.8/759.8 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 245.8/269.6 kB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.6/269.6 kB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.10.3 tiktoken-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need openai key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"categories_tagging.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store splits\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "\n",
    "prompt_template = \"\"\"Use the context below to assign a category that is relevant.\n",
    "After assigning a category, I want you to assign three tags in the chosen category that are relevant to the context\n",
    "\n",
    "Context: {context}\n",
    "info: {tagging}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"tagging\"])\n",
    "\n",
    "runnable_chain = PROMPT | ChatOpenAI() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(context, index, chain):\n",
    "    \"\"\"\n",
    "    Takes in query, index to search from, and llm chain to generate answer\n",
    "    \"\"\"\n",
    "    answer = chain.invoke({\"context\": context, \"tagging\": index})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SECTION 1. Chapter 20 Section 23 of the General Laws, as appearing in the 2020 Official Edition, is hereby amended by inserting the following after section (f): -\n",
      "\t(g) Notwithstanding any general or special law to the contrary, the department of agricultural resources, \n",
      "    with the approval of the co-holder, if any, in its sole discretion, may allow for storm water mitigation or nitrogen mitigation purposes, \n",
      "    in nitrogen sensitive embayment watersheds, uncultivated, planted or other storm water mitigation infrastructure within 200 feet of any resource area in any parcel \n",
      "    that has been accepted into the Massachusetts Agricultural Preservation Restriction program.\n",
      "Category: Environmental Regulations\n",
      "\n",
      "Tags:\n",
      "1. Storm water mitigation\n",
      "2. Nitrogen mitigation\n",
      "3. Massachusetts Agricultural Preservation Restriction program\n"
     ]
    }
   ],
   "source": [
    "info = \"\"\"\n",
    "SECTION 1. Chapter 20 Section 23 of the General Laws, as appearing in the 2020 Official Edition, is hereby amended by inserting the following after section (f): -\n",
    "\t(g) Notwithstanding any general or special law to the contrary, the department of agricultural resources, \n",
    "    with the approval of the co-holder, if any, in its sole discretion, may allow for storm water mitigation or nitrogen mitigation purposes, \n",
    "    in nitrogen sensitive embayment watersheds, uncultivated, planted or other storm water mitigation infrastructure within 200 feet of any resource area in any parcel \n",
    "    that has been accepted into the Massachusetts Agricultural Preservation Restriction program.\"\"\"\n",
    "\n",
    "answer = answer_question(info, vectorstore, runnable_chain)\n",
    "print(info)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
